{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-05T10:43:47.951187Z",
     "start_time": "2024-12-05T10:43:29.265180Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data as pdr\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Utility function to split sequences\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define a function for generating a sequence of future predictions\n",
    "def sequence_generation(dataset, sc, model, n_steps, steps_future, features):\n",
    "    high_dataset = dataset.iloc[-(len(dataset) + n_steps):][\"High\"]\n",
    "    high_dataset = sc.transform(high_dataset.values.reshape(-1, 1))\n",
    "    inputs = high_dataset[:n_steps]\n",
    "\n",
    "    for _ in range(steps_future):\n",
    "        curr_pred = model.predict(inputs[-n_steps:].reshape(1, n_steps, features), verbose=0)\n",
    "        inputs = np.append(inputs, curr_pred, axis=0)\n",
    "\n",
    "    return sc.inverse_transform(inputs[n_steps:])\n",
    "\n",
    "# Generic training function for RNN or LSTM\n",
    "def train_model(model_type, X_train, y_train, n_steps, features, sc, test_set, dataset, epochs=10, batch_size=32, verbose=1, steps_in_future=25, save_model_path=None):\n",
    "    model = Sequential()\n",
    "    if model_type == \"RNN\":\n",
    "        model.add(SimpleRNN(units=125, input_shape=(n_steps, features)))\n",
    "    elif model_type == \"LSTM\":\n",
    "        model.add(LSTM(units=125, input_shape=(n_steps, features)))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'RNN' or 'LSTM'.\")\n",
    "        \n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=\"RMSprop\", loss=\"mse\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    # Prepare test data\n",
    "    inputs = sc.transform(test_set.reshape(-1, 1))\n",
    "    X_test, y_test = split_sequence(inputs, n_steps)\n",
    "    X_test = X_test.reshape(-1, n_steps, features)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predicted_stock_price = model.predict(X_test, verbose=0)\n",
    "    predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "    rmse = np.sqrt(mean_squared_error(sc.inverse_transform(y_test.reshape(-1, 1)), predicted_stock_price))\n",
    "    print(f\"The root mean squared error is {rmse:.2f}.\")\n",
    "    \n",
    "    # Generate future predictions\n",
    "    results = sequence_generation(dataset, sc, model, n_steps, steps_in_future, features)\n",
    "    print(\"Generated sequence of future predictions:\", results.flatten())\n",
    "    \n",
    "    # Save the model\n",
    "    if save_model_path:\n",
    "        model.save(save_model_path)\n",
    "        print(f\"Model saved successfully at {save_model_path}.\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load historical stock price data for AAPL\n",
    "yf.pdr_override()\n",
    "dataset = pdr.get_data_yahoo('AAPL', start='2012-01-01', end=datetime.now())\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "train_end = datetime(2020, 1, 1)\n",
    "training_set = dataset[dataset.index < train_end][\"High\"].values\n",
    "test_set = dataset[dataset.index >= train_end][\"High\"].values\n",
    "\n",
    "# Scale dataset values\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set.reshape(-1, 1))\n",
    "\n",
    "# Create overlapping window batches\n",
    "n_steps = 50\n",
    "features = 1\n",
    "X_train, y_train = split_sequence(training_set_scaled, n_steps)\n",
    "\n",
    "# Reshape X_train for compatibility\n",
    "X_train = X_train.reshape(X_train.shape[0], n_steps, features)\n",
    "\n",
    "# Train RNN model\n",
    "model_rnn = train_model(\"RNN\", X_train, y_train, n_steps, features, sc, test_set, dataset, epochs=10, batch_size=32, steps_in_future=25, save_model_path=\"output/model_rnn.h5\")\n",
    "\n",
    "# Train LSTM model\n",
    "model_lstm = train_model(\"LSTM\", X_train, y_train, n_steps, features, sc, test_set, dataset, epochs=10, batch_size=32, steps_in_future=25, save_model_path=\"output/model_lstm.h5\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfinance: pandas_datareader support is deprecated & semi-broken so will be removed in a future verison. Just use yfinance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "Epoch 1/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.1039\n",
      "Epoch 2/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0026\n",
      "Epoch 3/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0019\n",
      "Epoch 4/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 8.8233e-04\n",
      "Epoch 5/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 4.2676e-04\n",
      "Epoch 6/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.9091e-04\n",
      "Epoch 7/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.2181e-04\n",
      "Epoch 8/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.6120e-04\n",
      "Epoch 9/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.8716e-04\n",
      "Epoch 10/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.2924e-04\n",
      "The root mean squared error is 13.17.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence of future predictions: [21.04286473 21.42901189 21.56553064 21.90959403 22.15586644 22.32975219\n",
      " 22.55957813 22.88607169 22.95050824 23.19456743 23.34252907 23.60179486\n",
      " 23.74222291 23.99980055 24.19401471 24.44751713 24.67536195 24.9512145\n",
      " 25.19688065 25.48828926 25.74178462 25.98915746 26.27167613 26.53618816\n",
      " 26.76120204]\n",
      "Model saved successfully at output/model_rnn.h5.\n",
      "Epoch 1/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - loss: 0.0180\n",
      "Epoch 2/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 0.0014\n",
      "Epoch 3/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 9.2404e-04\n",
      "Epoch 4/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - loss: 5.9626e-04\n",
      "Epoch 5/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - loss: 6.1198e-04\n",
      "Epoch 6/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 4.1995e-04\n",
      "Epoch 7/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 3.8861e-04\n",
      "Epoch 8/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 3.4433e-04\n",
      "Epoch 9/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 4.2390e-04\n",
      "Epoch 10/10\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 3.7596e-04\n",
      "The root mean squared error is 5.75.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence of future predictions: [20.32620572 20.46905349 20.60137966 20.7253317  20.84303767 20.95604276\n",
      " 21.06547696 21.17216141 21.27670588 21.37955912 21.48106572 21.58148116\n",
      " 21.68100177 21.77978288 21.87793568 21.97555812 22.07273139 22.1694996\n",
      " 22.26591395 22.36201326 22.45782489 22.55336824 22.64866363 22.74373575\n",
      " 22.83858285]\n",
      "Model saved successfully at output/model_lstm.h5.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T10:44:10.065020Z",
     "start_time": "2024-12-05T10:44:10.028653Z"
    }
   },
   "cell_type": "code",
   "source": "model_lstm.summary()",
   "id": "2bc2c165cb063840",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m125\u001B[0m)            │        \u001B[38;5;34m63,500\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m126\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">63,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m127,254\u001B[0m (497.09 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,254</span> (497.09 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m63,626\u001B[0m (248.54 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,626</span> (248.54 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m63,628\u001B[0m (248.55 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,628</span> (248.55 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T10:44:43.216379Z",
     "start_time": "2024-12-05T10:44:43.211528Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fc1f10cf54f63263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73b0647ac899de32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
